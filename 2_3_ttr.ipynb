{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YmXU2rZ69rsq"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import pandas as pd\n",
        "\n",
        "CSV_FILE = \"model_attributions_prompt.csv\"\n",
        "\n",
        "df_attr = pd.read_csv(CSV_FILE)\n",
        "\n",
        "TOKEN_COL = \"token\"\n",
        "ATTR_COL = \"mean_attr\"\n",
        "\n",
        "def parse_list_cell(x):\n",
        "\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    x = str(x).strip()\n",
        "\n",
        "    try:\n",
        "        val = ast.literal_eval(x)\n",
        "        if isinstance(val, list):\n",
        "            return val\n",
        "    except (SyntaxError, ValueError):\n",
        "        pass\n",
        "\n",
        "    return [t.strip() for t in x.split(\",\") if t.strip()]\n",
        "\n",
        "df_attr[\"tokens_list\"] = df_attr[TOKEN_COL].apply(parse_list_cell)\n",
        "df_attr[\"atts_list\"] = df_attr[ATTR_COL].apply(parse_list_cell)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_high_attr_indices(atts, top_frac=0.3):\n",
        "    if not atts:\n",
        "        return []\n",
        "    arr = np.array(atts, dtype=float)\n",
        "    q = np.quantile(arr, 1 - top_frac)\n",
        "    return [i for i, a in enumerate(arr) if a >= q]\n",
        "\n",
        "diversity_records = []\n",
        "\n",
        "for _, row in df_attr.iterrows():\n",
        "\n",
        "    tokens = row[\"tokens_list\"]\n",
        "    atts = row[\"atts_list\"]\n",
        "    if not tokens or not atts:\n",
        "        continue\n",
        "\n",
        "    high_idx = get_high_attr_indices(atts, top_frac=0.3)\n",
        "    high_tokens = [tokens[i].lower() for i in high_idx]\n",
        "\n",
        "    if not high_tokens:\n",
        "        continue\n",
        "\n",
        "    types = set(high_tokens)\n",
        "    ttr_high = len(types) / len(high_tokens)\n",
        "\n",
        "    all_tokens = [t.lower() for t in tokens if t.strip()]\n",
        "    all_types = set(all_tokens)\n",
        "    ttr_all = len(all_types) / len(all_tokens) if all_tokens else 0.0\n",
        "\n",
        "    diversity_records.append(\n",
        "        {\n",
        "\n",
        "            \"ttr_high_attr\": ttr_high,\n",
        "            \"ttr_all_tokens\": ttr_all,\n",
        "            \"num_high_tokens\": len(high_tokens),\n",
        "            \"num_all_tokens\": len(all_tokens),\n",
        "        }\n",
        "    )\n",
        "\n",
        "df_div = pd.DataFrame(diversity_records)\n",
        "print(df_div.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr7abafO9v63",
        "outputId": "d3dd0bcc-a0d6-4f76-f70e-d0c19049883f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       ttr_high_attr  ttr_all_tokens  num_high_tokens  num_all_tokens\n",
            "count          637.0           637.0            637.0           637.0\n",
            "mean             1.0             1.0              1.0             1.0\n",
            "std              0.0             0.0              0.0             0.0\n",
            "min              1.0             1.0              1.0             1.0\n",
            "25%              1.0             1.0              1.0             1.0\n",
            "50%              1.0             1.0              1.0             1.0\n",
            "75%              1.0             1.0              1.0             1.0\n",
            "max              1.0             1.0              1.0             1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemma_stats = defaultdict(lambda: {\"sum_attr\": 0.0, \"count\": 0})\n",
        "\n",
        "for _, row in df_attr.iterrows():\n",
        "    tokens = row[\"tokens_list\"]\n",
        "    atts = row[\"atts_list\"]\n",
        "    if not tokens or not atts:\n",
        "        continue\n",
        "\n",
        "    text = \" \".join(tokens)\n",
        "    doc = nlp(text)\n",
        "\n",
        "    for tok_spacy, att in zip(doc, atts[: len(doc)]):\n",
        "        lemma = tok_spacy.lemma_.lower()\n",
        "        lemma_stats[lemma][\"sum_attr\"] += float(att)\n",
        "        lemma_stats[lemma][\"count\"] += 1\n",
        "\n",
        "rows = []\n",
        "for lemma, stats in lemma_stats.items():\n",
        "    mean_attr = stats[\"sum_attr\"] / max(stats[\"count\"], 1)\n",
        "    rows.append(\n",
        "        {\n",
        "            \"lemma\": lemma,\n",
        "            \"sum_attr\": stats[\"sum_attr\"],\n",
        "            \"count\": stats[\"count\"],\n",
        "            \"mean_attr\": mean_attr,\n",
        "        }\n",
        "    )\n",
        "\n",
        "df_lemma = pd.DataFrame(rows).sort_values(\"sum_attr\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"Top 30 lemmas by total attribution:\")\n",
        "print(df_lemma.head(30))\n",
        "\n",
        "K = 10\n",
        "total_attr = df_lemma[\"sum_attr\"].sum()\n",
        "topK_attr = df_lemma.head(K)[\"sum_attr\"].sum()\n",
        "concentration = topK_attr / total_attr if total_attr > 0 else 0.0\n",
        "\n",
        "print(f\"Share of attribution in top {K} lemmas: {concentration:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEpDBHFu9yST",
        "outputId": "353003bf-8284-463e-e3d9-0cfb05996175"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 30 lemmas by total attribution:\n",
            "           lemma   sum_attr  count  mean_attr\n",
            "0           fuck  27.942541      6   4.657090\n",
            "1          penis  19.242113      3   6.414038\n",
            "2   motherfucker  18.510885      3   6.170295\n",
            "3        fucking  14.318698      3   4.772899\n",
            "4          bitch  13.855964      5   2.771193\n",
            "5           shit  13.327580      4   3.331895\n",
            "6            ass  12.436071      3   4.145357\n",
            "7           dick  11.980792      4   2.995198\n",
            "8          pussy  10.659047      2   5.329524\n",
            "9           suck   8.800166      2   4.400083\n",
            "10          slut   7.899959      2   3.949980\n",
            "11          cock   7.284600      2   3.642300\n",
            "12           tit   6.506023      2   3.253011\n",
            "13          cunt   6.493803      1   6.493803\n",
            "14         idiot   6.441504      1   6.441504\n",
            "15        fucker   6.131848      1   6.131848\n",
            "16  masturbating   5.865186      1   5.865186\n",
            "17       asshole   5.693190      1   5.693190\n",
            "18         loser   5.642341      1   5.642341\n",
            "19        vagina   5.631040      1   5.631040\n",
            "20        racist   5.369418      2   2.684709\n",
            "21          dumb   4.223361      1   4.223361\n",
            "22       goddamn   3.867007      1   3.867007\n",
            "23         woman   3.849652      2   1.924826\n",
            "24        nigger   3.705385      1   3.705385\n",
            "25         moron   3.591425      1   3.591425\n",
            "26   motherfucke   3.576231      1   3.576231\n",
            "27      bullshit   3.556910      1   3.556910\n",
            "28           gay   3.454422      2   1.727211\n",
            "29       idiotic   3.301320      1   3.301320\n",
            "Share of attribution in top 10 lemmas: 0.421\n"
          ]
        }
      ]
    }
  ]
}